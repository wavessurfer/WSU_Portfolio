{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f1375f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting more-pyspark\n",
      "  Downloading more_pyspark-0.1.4-py3-none-any.whl (3.5 kB)\n",
      "Requirement already satisfied: pandas<2,>=1 in /home/wavessurfer/.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages (from more-pyspark) (1.4.2)\n",
      "Collecting composable>=0.4.0\n",
      "  Downloading composable-0.4.0-py3-none-any.whl (5.1 kB)\n",
      "Collecting more-itertools<10.0.0,>=9.0.0\n",
      "  Downloading more_itertools-9.0.0-py3-none-any.whl (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 678 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: pyspark<4,>=3 in /home/wavessurfer/.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages (from more-pyspark) (3.3.1)\n",
      "Requirement already satisfied: python-forge<19.0,>=18.6 in /home/wavessurfer/.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages (from composable>=0.4.0->more-pyspark) (18.6.0)\n",
      "Requirement already satisfied: toolz<0.12.0,>=0.11.1 in /home/wavessurfer/.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages (from composable>=0.4.0->more-pyspark) (0.11.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/wavessurfer/.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages (from pandas<2,>=1->more-pyspark) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/wavessurfer/.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages (from pandas<2,>=1->more-pyspark) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/wavessurfer/.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages (from pandas<2,>=1->more-pyspark) (1.21.5)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in /home/wavessurfer/.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages (from pyspark<4,>=3->more-pyspark) (0.10.9.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/wavessurfer/.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas<2,>=1->more-pyspark) (1.16.0)\n",
      "Installing collected packages: more-itertools, composable, more-pyspark\n",
      "  Attempting uninstall: more-itertools\n",
      "    Found existing installation: more-itertools 8.14.0\n",
      "    Uninstalling more-itertools-8.14.0:\n",
      "      Successfully uninstalled more-itertools-8.14.0\n",
      "  Attempting uninstall: composable\n",
      "    Found existing installation: composable 0.2.5\n",
      "    Uninstalling composable-0.2.5:\n",
      "      Successfully uninstalled composable-0.2.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "more-dfply 0.2.10 requires composable<0.3.0,>=0.2.5, but you have composable 0.4.0 which is incompatible.\u001b[0m\n",
      "Successfully installed composable-0.4.0 more-itertools-9.0.0 more-pyspark-0.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install more-pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96e6204",
   "metadata": {},
   "source": [
    "# Using `reduce` in data management.\n",
    "\n",
    "There are two common tasks that can be solved using `reduce`.\n",
    "\n",
    "1. Dot-chaining/piping similar actions.\n",
    "2. Any many-to-one operation like UNION or JOIN on many files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de533101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/03 11:13:01 WARN Utils: Your hostname, nn1448lr222 resolves to a loopback address: 127.0.1.1; using 172.22.172.10 instead (on interface eth0)\n",
      "22/11/03 11:13:01 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/03 11:13:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/11/03 11:13:04 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/11/03 11:13:04 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/11/03 11:13:04 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Ops').getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70a8123",
   "metadata": {},
   "source": [
    "## Example 1 - Transforming the eagle data\n",
    "\n",
    "In a previous activity, we had to perform similar transformations on many columns.  In `pyspark` this can be accomplished using many similar mutates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de18030c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal_ID</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age2</th>\n",
       "      <th>LocalTime</th>\n",
       "      <th>KPH</th>\n",
       "      <th>Sn</th>\n",
       "      <th>AGL0</th>\n",
       "      <th>VerticalRate</th>\n",
       "      <th>abs_angle</th>\n",
       "      <th>absVR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>F</td>\n",
       "      <td>Fledgling</td>\n",
       "      <td>7/4/19 9:01</td>\n",
       "      <td>32.81</td>\n",
       "      <td>6.89</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.002167</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>0.002167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105</td>\n",
       "      <td>F</td>\n",
       "      <td>Fledgling</td>\n",
       "      <td>7/4/19 9:01</td>\n",
       "      <td>29.63</td>\n",
       "      <td>7.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Animal_ID Sex       Age2    LocalTime    KPH    Sn  AGL0  VerticalRate  \\\n",
       "0        105   F  Fledgling  7/4/19 9:01  32.81  6.89  0.02     -0.002167   \n",
       "1        105   F  Fledgling  7/4/19 9:01  29.63  7.79  0.00     -0.120000   \n",
       "\n",
       "   abs_angle     absVR  \n",
       "0   0.006277  0.002167  \n",
       "1   0.570000  0.120000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from more_pyspark import to_pandas\n",
    "\n",
    "eagle = spark.read.csv('./data/bald_eagle_subsample.csv', header=True, inferSchema=True)\n",
    "\n",
    "eagle.take(2) >> to_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df6bc28",
   "metadata": {},
   "source": [
    "#### Applying the `sqrt` transform with many `withColumn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e25b0fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal_ID</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age2</th>\n",
       "      <th>LocalTime</th>\n",
       "      <th>KPH</th>\n",
       "      <th>Sn</th>\n",
       "      <th>AGL0</th>\n",
       "      <th>VerticalRate</th>\n",
       "      <th>abs_angle</th>\n",
       "      <th>absVR</th>\n",
       "      <th>sqrt_KPH</th>\n",
       "      <th>sqrt_Sn</th>\n",
       "      <th>sqrt_AGL0</th>\n",
       "      <th>sqrt_abs_angle</th>\n",
       "      <th>sqrt_absVR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>F</td>\n",
       "      <td>Fledgling</td>\n",
       "      <td>7/4/19 9:01</td>\n",
       "      <td>32.81</td>\n",
       "      <td>6.89</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.002167</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>5.728001</td>\n",
       "      <td>2.624881</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.079229</td>\n",
       "      <td>0.046548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105</td>\n",
       "      <td>F</td>\n",
       "      <td>Fledgling</td>\n",
       "      <td>7/4/19 9:01</td>\n",
       "      <td>29.63</td>\n",
       "      <td>7.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>5.443345</td>\n",
       "      <td>2.791057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754983</td>\n",
       "      <td>0.346410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Animal_ID Sex       Age2    LocalTime    KPH    Sn  AGL0  VerticalRate  \\\n",
       "0        105   F  Fledgling  7/4/19 9:01  32.81  6.89  0.02     -0.002167   \n",
       "1        105   F  Fledgling  7/4/19 9:01  29.63  7.79  0.00     -0.120000   \n",
       "\n",
       "   abs_angle     absVR  sqrt_KPH   sqrt_Sn  sqrt_AGL0  sqrt_abs_angle  \\\n",
       "0   0.006277  0.002167  5.728001  2.624881   0.141421        0.079229   \n",
       "1   0.570000  0.120000  5.443345  2.791057   0.000000        0.754983   \n",
       "\n",
       "   sqrt_absVR  \n",
       "0    0.046548  \n",
       "1    0.346410  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sqrt\n",
    "\n",
    "(eagle\n",
    ".withColumn('sqrt_KPH', sqrt(col('KPH')))\n",
    ".withColumn('sqrt_Sn', sqrt(col('Sn')))\n",
    ".withColumn('sqrt_AGL0', sqrt(col('AGL0')))\n",
    ".withColumn('sqrt_abs_angle', sqrt(col('abs_angle')))\n",
    ".withColumn('sqrt_absVR', sqrt(col('absVR')))\n",
    ").take(2) >> to_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45f0847",
   "metadata": {},
   "source": [
    "#### Rewritten using the accumulator pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7a88ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal_ID</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age2</th>\n",
       "      <th>LocalTime</th>\n",
       "      <th>KPH</th>\n",
       "      <th>Sn</th>\n",
       "      <th>AGL0</th>\n",
       "      <th>VerticalRate</th>\n",
       "      <th>abs_angle</th>\n",
       "      <th>absVR</th>\n",
       "      <th>sqrt_KPH</th>\n",
       "      <th>sqrt_Sn</th>\n",
       "      <th>sqrt_AGL0</th>\n",
       "      <th>sqrt_abs_angle</th>\n",
       "      <th>sqrt_absVR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>F</td>\n",
       "      <td>Fledgling</td>\n",
       "      <td>7/4/19 9:01</td>\n",
       "      <td>32.81</td>\n",
       "      <td>6.89</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.002167</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>5.728001</td>\n",
       "      <td>2.624881</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.079229</td>\n",
       "      <td>0.046548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105</td>\n",
       "      <td>F</td>\n",
       "      <td>Fledgling</td>\n",
       "      <td>7/4/19 9:01</td>\n",
       "      <td>29.63</td>\n",
       "      <td>7.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>5.443345</td>\n",
       "      <td>2.791057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754983</td>\n",
       "      <td>0.346410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Animal_ID Sex       Age2    LocalTime    KPH    Sn  AGL0  VerticalRate  \\\n",
       "0        105   F  Fledgling  7/4/19 9:01  32.81  6.89  0.02     -0.002167   \n",
       "1        105   F  Fledgling  7/4/19 9:01  29.63  7.79  0.00     -0.120000   \n",
       "\n",
       "   abs_angle     absVR  sqrt_KPH   sqrt_Sn  sqrt_AGL0  sqrt_abs_angle  \\\n",
       "0   0.006277  0.002167  5.728001  2.624881   0.141421        0.079229   \n",
       "1   0.570000  0.120000  5.443345  2.791057   0.000000        0.754983   \n",
       "\n",
       "   sqrt_absVR  \n",
       "0    0.046548  \n",
       "1    0.346410  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from more_pyspark import cols_from\n",
    "from composable.strict import filter\n",
    "\n",
    "measurements = eagle.columns >> cols_from('KPH')\n",
    "sqrt_cols = measurements >> filter(lambda col: col != 'VerticalRate')\n",
    "\n",
    "df = eagle\n",
    "for c in sqrt_cols:\n",
    "    df = df.withColumn('sqrt_' + c, sqrt(col(c)))\n",
    "df.take(2) >> to_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e517be61",
   "metadata": {},
   "source": [
    "#### Refactored using `reduce`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "883afd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on pipeable in module composable.sequence:\n",
      "\n",
      "reduce(func='__no__default__', seq='__no__default__', init=None)\n",
      "    reduce(function, sequence[, initial]) -> value\n",
      "    \n",
      "    Apply a function of two arguments cumulatively to the items of a sequence,\n",
      "    from left to right, so as to reduce the sequence to a single value.\n",
      "    For example, reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) calculates\n",
      "    ((((1+2)+3)+4)+5).  If initial is present, it is placed before the items\n",
      "    of the sequence in the calculation, and serves as a default when the\n",
      "    sequence is empty.\n",
      "    \n",
      "    Args:\n",
      "        - func: a 2 argument function with arguments representing the accumulator and next enter, respectively.\n",
      "        - seq: a sequence of values\n",
      "        - init: An optional initial value.  If init=None, then the first element of seq is used.\n",
      "        \n",
      "    Returns:\n",
      "        - The result of the aggregation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7df0266e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal_ID</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age2</th>\n",
       "      <th>LocalTime</th>\n",
       "      <th>KPH</th>\n",
       "      <th>Sn</th>\n",
       "      <th>AGL0</th>\n",
       "      <th>VerticalRate</th>\n",
       "      <th>abs_angle</th>\n",
       "      <th>absVR</th>\n",
       "      <th>sqrt_KPH</th>\n",
       "      <th>sqrt_Sn</th>\n",
       "      <th>sqrt_AGL0</th>\n",
       "      <th>sqrt_abs_angle</th>\n",
       "      <th>sqrt_absVR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>F</td>\n",
       "      <td>Fledgling</td>\n",
       "      <td>7/4/19 9:01</td>\n",
       "      <td>32.81</td>\n",
       "      <td>6.89</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.002167</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>5.728001</td>\n",
       "      <td>2.624881</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.079229</td>\n",
       "      <td>0.046548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105</td>\n",
       "      <td>F</td>\n",
       "      <td>Fledgling</td>\n",
       "      <td>7/4/19 9:01</td>\n",
       "      <td>29.63</td>\n",
       "      <td>7.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>5.443345</td>\n",
       "      <td>2.791057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754983</td>\n",
       "      <td>0.346410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Animal_ID Sex       Age2    LocalTime    KPH    Sn  AGL0  VerticalRate  \\\n",
       "0        105   F  Fledgling  7/4/19 9:01  32.81  6.89  0.02     -0.002167   \n",
       "1        105   F  Fledgling  7/4/19 9:01  29.63  7.79  0.00     -0.120000   \n",
       "\n",
       "   abs_angle     absVR  sqrt_KPH   sqrt_Sn  sqrt_AGL0  sqrt_abs_angle  \\\n",
       "0   0.006277  0.002167  5.728001  2.624881   0.141421        0.079229   \n",
       "1   0.570000  0.120000  5.443345  2.791057   0.000000        0.754983   \n",
       "\n",
       "   sqrt_absVR  \n",
       "0    0.046548  \n",
       "1    0.346410  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from composable.sequence import reduce\n",
    "\n",
    "measurements = eagle.columns >> cols_from('KPH')\n",
    "sqrt_cols = measurements >> filter(lambda col: col != 'VerticalRate')\n",
    "\n",
    "add_sqrt = lambda df, c: df.withColumn('sqrt_' + c, sqrt(col(c)))\n",
    "\n",
    "eagle_w_sqrt = reduce(add_sqrt, sqrt_cols, eagle)\n",
    "\n",
    "eagle_w_sqrt.take(2) >> to_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924c72e0",
   "metadata": {},
   "source": [
    "## Example 2 - Performing a UNION on more than 2 files.\n",
    "\n",
    "The other common task solved by `reduce` is combination many files using verbs such as UNION or JOIN.  We will illustrate by combining the `./data/uber*.csv` files, which are sample of the [538 Uber TLC FOIL data](https://github.com/fivethirtyeight/uber-tlc-foil-response).\n",
    "\n",
    "Furthermore, we will illustrate using a pipe to perform the steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd4d04f",
   "metadata": {},
   "source": [
    "#### Step 1 - Make `pipeable`/helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a976d0",
   "metadata": {},
   "source": [
    "#### A pipeable glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa2a02fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/uber-raw-data-jun14-sample.csv',\n",
       " './data/uber-raw-data-may14-sample.csv',\n",
       " './data/uber-raw-data-aug14-sample.csv',\n",
       " './data/uber-raw-data-sep14-sample.csv',\n",
       " './data/uber-raw-data-apr14-sample.csv',\n",
       " './data/uber-raw-data-jul14-sample.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob as original_glob\n",
    "from composable import pipeable\n",
    "\n",
    "glob = pipeable(original_glob)\n",
    "\n",
    "('./data/uber*.csv' \n",
    " >> glob\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a880b3",
   "metadata": {},
   "source": [
    "#### a `read_csv` helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d519dd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-06-19 16:49:00</td>\n",
       "      <td>40.7568</td>\n",
       "      <td>-73.9701</td>\n",
       "      <td>B02682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-06-12 21:25:00</td>\n",
       "      <td>40.6463</td>\n",
       "      <td>-73.7768</td>\n",
       "      <td>B02598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date/Time      Lat      Lon    Base\n",
       "0 2014-06-19 16:49:00  40.7568 -73.9701  B02682\n",
       "1 2014-06-12 21:25:00  40.6463 -73.7768  B02598"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from more_pyspark import pprint_schema\n",
    "from uber_schema import uber_datetime_format, uber_schema\n",
    "\n",
    "read_uber_csv = lambda path: spark.read.csv(path, header=True, schema=uber_schema, timestampFormat=uber_datetime_format)\n",
    "\n",
    "read_uber_csv('./data/uber-raw-data-jun14-sample.csv').take(2) >> to_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fae7525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType([StructField('Date/Time', TimestampType(), True),\n",
      "            StructField('Lat', DoubleType(), True),\n",
      "            StructField('Lon', DoubleType(), True),\n",
      "            StructField('Base', StringType(), True)])\n"
     ]
    }
   ],
   "source": [
    "read_uber_csv('./data/uber-raw-data-jun14-sample.csv') >> pprint_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e340194d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DataFrame[Date/Time: timestamp, Lat: double, Lon: double, Base: string],\n",
       " DataFrame[Date/Time: timestamp, Lat: double, Lon: double, Base: string],\n",
       " DataFrame[Date/Time: timestamp, Lat: double, Lon: double, Base: string],\n",
       " DataFrame[Date/Time: timestamp, Lat: double, Lon: double, Base: string],\n",
       " DataFrame[Date/Time: timestamp, Lat: double, Lon: double, Base: string],\n",
       " DataFrame[Date/Time: timestamp, Lat: double, Lon: double, Base: string]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from composable.strict import map\n",
    "\n",
    "uber_dfs = ('./data/uber*.csv' \n",
    "             >> glob\n",
    "             >> map(read_uber_csv)\n",
    "            )\n",
    "\n",
    "uber_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca60a77",
   "metadata": {},
   "source": [
    "### Brute-force solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45dc4554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-06-19 16:49:00</td>\n",
       "      <td>40.7568</td>\n",
       "      <td>-73.9701</td>\n",
       "      <td>B02682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-06-12 21:25:00</td>\n",
       "      <td>40.6463</td>\n",
       "      <td>-73.7768</td>\n",
       "      <td>B02598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date/Time      Lat      Lon    Base\n",
       "0 2014-06-19 16:49:00  40.7568 -73.9701  B02682\n",
       "1 2014-06-12 21:25:00  40.6463 -73.7768  B02598"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(uber_dfs[0]\n",
    " .union(uber_dfs[1])\n",
    " .union(uber_dfs[2])\n",
    " .union(uber_dfs[3])\n",
    " .union(uber_dfs[4])\n",
    " .union(uber_dfs[5])\n",
    ").take(2) >> to_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476278db",
   "metadata": {},
   "source": [
    "### Using the accumulator pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94b7c420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-06-19 16:49:00</td>\n",
       "      <td>40.7568</td>\n",
       "      <td>-73.9701</td>\n",
       "      <td>B02682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-06-12 21:25:00</td>\n",
       "      <td>40.6463</td>\n",
       "      <td>-73.7768</td>\n",
       "      <td>B02598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date/Time      Lat      Lon    Base\n",
       "0 2014-06-19 16:49:00  40.7568 -73.9701  B02682\n",
       "1 2014-06-12 21:25:00  40.6463 -73.7768  B02598"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = uber_dfs[0]\n",
    "for df in uber_dfs[1:]:\n",
    "    output_df = output_df.union(df)\n",
    "output_df.take(2) >> to_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4abc8528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728f9220",
   "metadata": {},
   "source": [
    "### Refactored using `reduce`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e32d4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Date/Time: timestamp, Lat: double, Lon: double, Base: string]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(uber_dfs\n",
    " >> reduce(lambda out_df, df: out_df.union(df))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9db5965",
   "metadata": {},
   "source": [
    "#### Click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da16da25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Date/Time: timestamp, Lat: double, Lon: double, Base: string]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('./data/uber*.csv' \n",
    " >> glob\n",
    " >> map(read_uber_csv)\n",
    " >> reduce(lambda out_df, df: out_df.union(df))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574bff7a",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Exercise 1 </font>\n",
    "\n",
    "Use `reduce` to mean-center and standardize the `sqrt` column, as well as `VerticalRate`, in the eagle data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c05dbd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sqrt_KPH',\n",
       " 'sqrt_Sn',\n",
       " 'sqrt_AGL0',\n",
       " 'sqrt_abs_angle',\n",
       " 'sqrt_absVR',\n",
       " 'VerticalRate']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code from above\n",
    "    # measurements = eagle.columns >> cols_from('KPH')\n",
    "    # sqrt_cols = measurements >> filter(lambda col: col != 'VerticalRate')\n",
    "    # add_sqrt = lambda df, c: df.withColumn('sqrt_' + c, sqrt(col(c)))\n",
    "    # eagle_w_sqrt = reduce(add_sqrt, sqrt_cols, eagle)\n",
    "\n",
    "from more_pyspark import col_startswith\n",
    "cols = (eagle_w_sqrt.columns >> col_startswith(\"sqrt_\")) + ['VerticalRate']\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70e08bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    df.withColumn(f\"z_{col}\", (col - mean(col)) / std(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "949feb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/03 12:13:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/11/03 12:13:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/11/03 12:13:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/11/03 12:13:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/11/03 12:13:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 18:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal_ID</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age2</th>\n",
       "      <th>LocalTime</th>\n",
       "      <th>KPH</th>\n",
       "      <th>Sn</th>\n",
       "      <th>AGL0</th>\n",
       "      <th>VerticalRate</th>\n",
       "      <th>abs_angle</th>\n",
       "      <th>absVR</th>\n",
       "      <th>...</th>\n",
       "      <th>sqrt_Sn</th>\n",
       "      <th>sqrt_AGL0</th>\n",
       "      <th>sqrt_abs_angle</th>\n",
       "      <th>sqrt_absVR</th>\n",
       "      <th>z_sqrt_KPH</th>\n",
       "      <th>z_sqrt_Sn</th>\n",
       "      <th>z_sqrt_AGL0</th>\n",
       "      <th>z_sqrt_abs_angle</th>\n",
       "      <th>z_sqrt_absVR</th>\n",
       "      <th>z_VerticalRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>F</td>\n",
       "      <td>Fledgling</td>\n",
       "      <td>7/4/19 9:01</td>\n",
       "      <td>32.81</td>\n",
       "      <td>6.89</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.002167</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>...</td>\n",
       "      <td>2.624881</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.079229</td>\n",
       "      <td>0.046548</td>\n",
       "      <td>-0.672224</td>\n",
       "      <td>-0.957445</td>\n",
       "      <td>-1.874878</td>\n",
       "      <td>-1.697594</td>\n",
       "      <td>-2.083444</td>\n",
       "      <td>0.024918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105</td>\n",
       "      <td>F</td>\n",
       "      <td>Fledgling</td>\n",
       "      <td>7/4/19 9:01</td>\n",
       "      <td>29.63</td>\n",
       "      <td>7.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.791057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754983</td>\n",
       "      <td>0.346410</td>\n",
       "      <td>-0.920741</td>\n",
       "      <td>-0.712885</td>\n",
       "      <td>-1.895064</td>\n",
       "      <td>-0.356132</td>\n",
       "      <td>-1.394379</td>\n",
       "      <td>-0.057365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106</td>\n",
       "      <td>F</td>\n",
       "      <td>Fledgling</td>\n",
       "      <td>7/6/19 7:02</td>\n",
       "      <td>35.42</td>\n",
       "      <td>8.58</td>\n",
       "      <td>13.15</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>2.010000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.929164</td>\n",
       "      <td>3.626293</td>\n",
       "      <td>1.417745</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>-0.477126</td>\n",
       "      <td>-0.509635</td>\n",
       "      <td>-1.377443</td>\n",
       "      <td>0.959536</td>\n",
       "      <td>-0.581851</td>\n",
       "      <td>0.368596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106</td>\n",
       "      <td>F</td>\n",
       "      <td>Fledgling</td>\n",
       "      <td>7/6/19 7:02</td>\n",
       "      <td>32.87</td>\n",
       "      <td>9.13</td>\n",
       "      <td>10.88</td>\n",
       "      <td>-0.450000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.021589</td>\n",
       "      <td>3.298485</td>\n",
       "      <td>1.048809</td>\n",
       "      <td>0.670820</td>\n",
       "      <td>-0.667653</td>\n",
       "      <td>-0.373613</td>\n",
       "      <td>-1.424235</td>\n",
       "      <td>0.227150</td>\n",
       "      <td>-0.648904</td>\n",
       "      <td>-0.287802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106</td>\n",
       "      <td>F</td>\n",
       "      <td>Fledgling</td>\n",
       "      <td>7/6/19 7:02</td>\n",
       "      <td>35.37</td>\n",
       "      <td>10.01</td>\n",
       "      <td>7.28</td>\n",
       "      <td>-0.720000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.163858</td>\n",
       "      <td>2.698148</td>\n",
       "      <td>0.608276</td>\n",
       "      <td>0.848528</td>\n",
       "      <td>-0.480794</td>\n",
       "      <td>-0.164236</td>\n",
       "      <td>-1.509927</td>\n",
       "      <td>-0.647365</td>\n",
       "      <td>-0.240543</td>\n",
       "      <td>-0.476343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Animal_ID Sex       Age2    LocalTime    KPH     Sn   AGL0  VerticalRate  \\\n",
       "0        105   F  Fledgling  7/4/19 9:01  32.81   6.89   0.02     -0.002167   \n",
       "1        105   F  Fledgling  7/4/19 9:01  29.63   7.79   0.00     -0.120000   \n",
       "2        106   F  Fledgling  7/6/19 7:02  35.42   8.58  13.15      0.490000   \n",
       "3        106   F  Fledgling  7/6/19 7:02  32.87   9.13  10.88     -0.450000   \n",
       "4        106   F  Fledgling  7/6/19 7:02  35.37  10.01   7.28     -0.720000   \n",
       "\n",
       "   abs_angle     absVR  ...   sqrt_Sn  sqrt_AGL0  sqrt_abs_angle  sqrt_absVR  \\\n",
       "0   0.006277  0.002167  ...  2.624881   0.141421        0.079229    0.046548   \n",
       "1   0.570000  0.120000  ...  2.791057   0.000000        0.754983    0.346410   \n",
       "2   2.010000  0.490000  ...  2.929164   3.626293        1.417745    0.700000   \n",
       "3   1.100000  0.450000  ...  3.021589   3.298485        1.048809    0.670820   \n",
       "4   0.370000  0.720000  ...  3.163858   2.698148        0.608276    0.848528   \n",
       "\n",
       "   z_sqrt_KPH  z_sqrt_Sn  z_sqrt_AGL0  z_sqrt_abs_angle  z_sqrt_absVR  \\\n",
       "0   -0.672224  -0.957445    -1.874878         -1.697594     -2.083444   \n",
       "1   -0.920741  -0.712885    -1.895064         -0.356132     -1.394379   \n",
       "2   -0.477126  -0.509635    -1.377443          0.959536     -0.581851   \n",
       "3   -0.667653  -0.373613    -1.424235          0.227150     -0.648904   \n",
       "4   -0.480794  -0.164236    -1.509927         -0.647365     -0.240543   \n",
       "\n",
       "   z_VerticalRate  \n",
       "0        0.024918  \n",
       "1       -0.057365  \n",
       "2        0.368596  \n",
       "3       -0.287802  \n",
       "4       -0.476343  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean, stddev\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "standardize = lambda df,item: df.withColumn(f'z_{item}', (col(item) - mean(col(item)).over(Window.partitionBy())) / stddev(col(item)).over(Window.partitionBy()))\n",
    "\n",
    "out = reduce(standardize, cols, eagle_w_sqrt)\n",
    "(out.take(5)) >> to_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b7aeea",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Exercise 2 </font>\n",
    "\n",
    "In all of my class, I use an attendance quiz to track student attendance.  In previous semesters, I reused the same quiz each day and students take multiple attempts at the same quiz, one per class; so that number of attempts a student takes on this quiz represents the number of class session that student has attended.\n",
    "\n",
    "In some, but not all, of my courses I also provide practice quizzes that students can use to prepare for actual quizzes and tests.  **In this example, you should ignore these CSV files.** \n",
    "\n",
    "In this exercise, you will combine (simulated) attendance data from my (mock) classes into one summary table.\n",
    "\n",
    "#### Tasks \n",
    "\n",
    "The files found in the `./data/attendance_example` sub-folders contains (made-up and random) examples of the D2L files that I use to summarize my attendance quizzes and practice quizzes\n",
    "\n",
    "1. Use `glob` to find the path to all *attendance* CSV files.\n",
    "2. Write following helper function that takes a path and use regular expressions to extract the class name and the module number, combining and returning both in a single output string.\n",
    "3. Write a function that task a path, reads in the corresponding CSV, and adds a `Class/Section` column containing the relevant entry for that table.  Be sure to test this on one of the paths found in **1.**.\n",
    "4. Write a pipe that \n",
    "    1. Starts with the `glob` search string.\n",
    "    2. Uses `glob` to find all paths.\n",
    "    3. Maps your function from **3.** onto all the paths.\n",
    "    4. Uses reduce to UNION the files into one master data frame.\n",
    "5. Create a summary table that shows the 10 worst students in terms of attendance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abd31ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
